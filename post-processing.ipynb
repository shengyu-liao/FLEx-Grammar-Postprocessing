{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15428f81",
   "metadata": {},
   "source": [
    "## Put this .ipynb file anywhere in your computer. Under the same directory, create a new folder and put the two text files 'words-surf.txt' and 'words-SIG.txt' into this new folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca445e78",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### words-SIG.txt\n",
    "1. If there is no ';' (semicolon) in a parse (meaning there's no morphology in this word): remove this parse and its corresponding word in 'words-surf.txt'\n",
    "\n",
    "### words-surf.txt\n",
    "2. '%0%WORD%' (e.g., '%0%клубдаяй%' in Legzi-QusarDialect): remove this word\n",
    "> reason: no template? Ask Beth\n",
    "3. '1.1' (e.g., 'Билесувардиз1.1яр' in Legzi-QusarDialect): remove this word\n",
    "> reason: no root? Ask Beth\n",
    "4. '{}' (denoting a missing gloss, e.g., 'áíhapi̱siyhobáchilííchi̱ki̱li{}ho̱' in Choctaw): remove this word\n",
    "5. '}' in Sena3: remove this word\n",
    "> reason: ?\n",
    "6. ',' (caused by the messy data in the database, e.g., 'i̱-, imchhobáchi' in Choctaw): remove this word\n",
    "7. '∅': u'\\u2205'\n",
    "> (representing a zero affix in Takwane): w = w.replace(u'\\u2205', '')\n",
    "8. 'ø': u'\\u00F8'\n",
    "> (representing a zero affix in Takwane): w = w.replace(u'\\u00F8', '')\n",
    "9. '^0' (representing a zero affix in Sena3): w = w.replace('^0', '')\n",
    "10. 'alt: ' in Sena3, e.g., 'pyalt: nkhundu-nkhundu': w = w.replace('alt: ', '')\n",
    "11. Replace space(s) in the word with '\\~': w = w.replace(' ', '\\~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd78dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process the data\n",
    "\n",
    "def postprocessing(folderName):\n",
    "    # Open files and read into data\n",
    "    inputFileName_surf = '.' + '/' + folderName + '/' + 'words-surf.txt'\n",
    "    inputFileName_SIG = '.' + '/' + folderName + '/' + 'words-SIG.txt'\n",
    "    \n",
    "    inputFile_surf = open(inputFileName_surf, 'r', encoding = 'utf-8')\n",
    "    inputFile_SIG = open(inputFileName_SIG, 'r', encoding = 'utf-8')\n",
    "    \n",
    "    # There is a space (U+0020) at the end of each word, but no space at the end of each parse\n",
    "    listOfWords_surf_input = [w.rstrip(' \\n') for w in inputFile_surf.readlines()]\n",
    "    listOfWords_SIG_input = [w.rstrip('\\n') for w in inputFile_SIG.readlines()]\n",
    "    \n",
    "    # Open files for writing the contents\n",
    "    outputFileName_surf = '.' + '/' + folderName + '/' + 'words-surf-preprocessed.txt'\n",
    "    outputFileName_SIG = '.' + '/' + folderName + '/' + 'words-SIG-preprocessed.txt'\n",
    "\n",
    "    outputFile_surf = open(outputFileName_surf, 'w', encoding = 'utf-8')\n",
    "    outputFile_SIG = open(outputFileName_SIG, 'w', encoding = 'utf-8')\n",
    "\n",
    "    # Join the word and parse separated by a unique character, e.g. '\\t' (tab)\n",
    "    listOfPairs = [pair[0] + '\\t' + pair[1] for pair in zip(listOfWords_surf_input, listOfWords_SIG_input)]\n",
    "    \n",
    "    # Convert all characters to lowercase\n",
    "    listOfPairs = [pair.lower() for pair in listOfPairs]\n",
    "    \n",
    "    listOfPairs_cleaned = []\n",
    "    \n",
    "    for pair in listOfPairs:\n",
    "        # If the pair does not contain any ';', it means the word does not contain any affixes\n",
    "        if ';' not in pair:\n",
    "            pass\n",
    "        # If the pair starts with '%'\n",
    "        elif pair.startswith('%', 0, 2):\n",
    "            pass\n",
    "        # If the pair contains '1.1'\n",
    "        elif '1.1' in pair:\n",
    "            pass\n",
    "        # If the pair contains '{' (or '{}')\n",
    "        elif '{' in pair:\n",
    "            pass\n",
    "        # If the pair contains '}'\n",
    "        elif '}' in pair:\n",
    "            pass\n",
    "        # If the pair contains ','\n",
    "        elif ',' in pair:\n",
    "            pass\n",
    "        else:\n",
    "            # Clean the pair\n",
    "            # Remove '∅': u'\\u2205'\n",
    "            pair = pair.replace(u'\\u2205', '')\n",
    "            # Remove 'ø': u'\\u00F8'\n",
    "            pair = pair.replace(u'\\u00F8', '')\n",
    "            # Remove '^0'\n",
    "            pair = pair.replace('^0', '')\n",
    "            # Remove 'alt: '\n",
    "            pair = pair.replace('alt: ', '')\n",
    "            \n",
    "            # Replace any character that is encoded as two characters (e.g. 'й')\n",
    "            # with a one-character symbol (e.g. '$')\n",
    "            # for Lezgi\n",
    "            pair = pair.replace('й', '$')\n",
    "            # for Sena\n",
    "            pair = pair.replace('á', '#')\n",
    "            \n",
    "            # Replace space with '~'\n",
    "            pair = pair.replace(' ', '~')\n",
    "            \n",
    "            listOfPairs_cleaned.append(pair)\n",
    "    \n",
    "    # Remove duplicate forms\n",
    "    listOfPairs_cleaned = set(listOfPairs_cleaned)\n",
    "    \n",
    "    listOfWords_surf_output = []\n",
    "    listOfWords_SIG_output = []\n",
    "    \n",
    "    for pair in listOfPairs_cleaned:\n",
    "        # for surf\n",
    "        surf = pair.split('\\t')[0]\n",
    "        # Separate each character with a space\n",
    "        surf = ' '.join(surf)\n",
    "        \n",
    "        # for Lezgi\n",
    "        surf = surf.replace('$', 'й')\n",
    "        \n",
    "        # for Sena\n",
    "        surf = surf.replace('#', 'á')\n",
    "        \n",
    "        listOfWords_surf_output.append(surf)\n",
    "        \n",
    "        # for SIG\n",
    "        SIG = pair.split('\\t')[1]\n",
    "        # Convert parses to uppercase\n",
    "        SIG = SIG.upper()\n",
    "        # Replace ';' with space\n",
    "        SIG = SIG.replace(';', ' ')\n",
    "        \n",
    "        listOfWords_SIG_output.append(SIG)\n",
    "    \n",
    "    # Write the results into 'outputFile_surf' and 'outputFile_SIG', respectively\n",
    "    outputFile_surf.write('\\n'.join(listOfWords_surf_output))\n",
    "    outputFile_SIG.write('\\n'.join(listOfWords_SIG_output))\n",
    "    \n",
    "    # Close files\n",
    "    inputFile_surf.close()\n",
    "    inputFile_SIG.close()\n",
    "    \n",
    "    outputFile_surf.close()\n",
    "    outputFile_SIG.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27608037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the postprocessing() function by passing the name of the folder to this function\n",
    "# For example, if the folder's name is 'Sena', you can run postprocessing('Sena')\n",
    "# Then there will be two new files 'words-surf-preprocessed.txt' and 'words-SIG-preprocessed.txt'\n",
    "# in the same folder\n",
    "postprocessing('Lezgi-QusarDialect-nouns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a77dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the amount of tokens from data augmentation and after augmented data are post-processed\n",
    "\n",
    "def counting(folderName):\n",
    "    # Open files and read into data\n",
    "    inputFileName_surf = '.' + '/' + folderName + '/' + 'words-surf.txt'\n",
    "    inputFileName_SIG = '.' + '/' + folderName + '/' + 'words-SIG.txt'\n",
    "    \n",
    "    inputFile_surf = open(inputFileName_surf, 'r', encoding = 'utf-8')\n",
    "    inputFile_SIG = open(inputFileName_SIG, 'r', encoding = 'utf-8')\n",
    "    \n",
    "    listOfWords_surf_input = [w.rstrip('\\n') for w in inputFile_surf.readlines()]\n",
    "    listOfWords_SIG_input = [w.rstrip('\\n') for w in inputFile_SIG.readlines()]\n",
    "    \n",
    "    outputFileName_surf = '.' + '/' + folderName + '/' + 'words-surf-preprocessed.txt'\n",
    "    outputFileName_SIG = '.' + '/' + folderName + '/' + 'words-SIG-preprocessed.txt'\n",
    "    \n",
    "    outputFile_surf = open(outputFileName_surf, 'r', encoding = 'utf-8')\n",
    "    outputFile_SIG = open(outputFileName_SIG, 'r', encoding = 'utf-8')\n",
    "    \n",
    "    listOfWords_surf_output = [w.rstrip('\\n') for w in outputFile_surf.readlines()]\n",
    "    listOfWords_SIG_output = [w.rstrip('\\n') for w in outputFile_SIG.readlines()]\n",
    "    \n",
    "    print('There are', len(listOfWords_surf_input)-1, 'words in', folderName, 'words-surf.txt;')\n",
    "    print('There are', len(listOfWords_surf_output), 'words in', folderName,\n",
    "          'words-surf-preprocessed.txt.')\n",
    "    print('There are', len(listOfWords_SIG_input)-1, 'words in', folderName, 'words-SIG.txt;')\n",
    "    print('There are', len(listOfWords_SIG_output), 'words in', folderName,\n",
    "          'words-SIG-preprocessed.txt.')\n",
    "    \n",
    "    # Close files\n",
    "    inputFile_surf.close()\n",
    "    inputFile_SIG.close()\n",
    "    \n",
    "    outputFile_surf.close()\n",
    "    outputFile_SIG.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1942863 words in Lezgi-QusarDialect-nouns words-surf.txt;\n",
      "There are 851447 words in Lezgi-QusarDialect-nouns words-surf-preprocessed.txt.\n",
      "There are 1942863 words in Lezgi-QusarDialect-nouns words-SIG.txt;\n",
      "There are 851447 words in Lezgi-QusarDialect-nouns words-SIG-preprocessed.txt.\n"
     ]
    }
   ],
   "source": [
    "# Call the counting() function by passing the name of the folder to this function\n",
    "# For example, if the folder's name is 'Sena', you can run counting('Sena')\n",
    "# Then the amount of tokens in each file will be presented\n",
    "counting('Lezgi-QusarDialect-nouns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240d6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not want to sort the output, you can skip this function\n",
    "\n",
    "def sorting(folderName):\n",
    "    # Open files and read into data\n",
    "    inputFileName_surf_preprocessed = '.' + '/' + folderName + '/' + 'words-surf-preprocessed.txt'\n",
    "    inputFileName_SIG_preprocessed = '.' + '/' + folderName + '/' + 'words-SIG-preprocessed.txt'\n",
    "    \n",
    "    inputFile_surf_preprocessed = open(inputFileName_surf_preprocessed, 'r', encoding = 'utf-8')\n",
    "    inputFile_SIG_preprocessed = open(inputFileName_SIG_preprocessed, 'r', encoding = 'utf-8')\n",
    "        \n",
    "    listOfWords_surf_input_preprocessed = [w.rstrip('\\n') for w in inputFile_surf_preprocessed.readlines()]\n",
    "    listOfWords_SIG_input_preprocessed = [w.rstrip('\\n') for w in inputFile_SIG_preprocessed.readlines()]\n",
    "    \n",
    "    # Open files for writing the contents\n",
    "    outputFileName_surf_preprocessed = '.' + '/' + folderName + '/' + 'surf-preprocessed-sorted.txt'\n",
    "    outputFileName_SIG_preprocessed = '.' + '/' + folderName + '/' + 'SIG-preprocessed-sorted.txt'\n",
    "    \n",
    "    outputFile_surf_preprocessed = open(outputFileName_surf_preprocessed, 'w', encoding = 'utf-8')\n",
    "    outputFile_SIG_preprocessed = open(outputFileName_SIG_preprocessed, 'w', encoding = 'utf-8')\n",
    "    \n",
    "    # Join the word and parse separated by a unique char, e.g. '\\t'\n",
    "    listOfPairs_preprocessed = ([pair[0] + '\\t' + pair[1] for\n",
    "                                 pair in zip(listOfWords_surf_input_preprocessed,\n",
    "                                             listOfWords_SIG_input_preprocessed)])\n",
    "    \n",
    "    listOfPairs_preprocessed.sort()\n",
    "    \n",
    "    surf_preprocessed_sorted = [pair.split('\\t')[0] for pair in listOfPairs_preprocessed]\n",
    "    SIG_preprocessed_sorted = [pair.split('\\t')[1] for pair in listOfPairs_preprocessed]\n",
    "    \n",
    "    surf_preprocessed_results = '\\n'.join(surf_preprocessed_sorted)\n",
    "    SIG_preprocessed_results = '\\n'.join(SIG_preprocessed_sorted)\n",
    "    \n",
    "    outputFile_surf_preprocessed.write(surf_preprocessed_results)\n",
    "    outputFile_SIG_preprocessed.write(SIG_preprocessed_results)\n",
    "    \n",
    "    # Close the files\n",
    "    inputFile_surf_preprocessed.close()\n",
    "    inputFile_SIG_preprocessed.close()\n",
    "    \n",
    "    outputFile_surf_preprocessed.close()\n",
    "    outputFile_SIG_preprocessed.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6f95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the sorting() function by passing the name of the folder to this function\n",
    "# For example, if the folder's name is 'Sena', you can run sorting('Sena')\n",
    "# Then there will be two new files 'surf-preprocessed-sorted.txt' and 'SIG-preprocessed-sorted.txt'\n",
    "# in the same folder\n",
    "sorting('Lezgi-QusarDialect-nouns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5562c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
